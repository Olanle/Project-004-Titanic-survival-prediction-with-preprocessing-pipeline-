{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Olanle/Project-004-Titanic-survival-prediction-with-preprocessing-pipeline-/blob/main/004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "dMWc1BDutyCM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAiyWpFL4LRw",
        "outputId": "f614ee72-6148-4972-8c50-f42bda1ef3a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/Titanic-Dataset.csv\")\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGxu5-2D6zQ-",
        "outputId": "439a1c9c-6fb0-41a6-cd15-097dffd7f50b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shape:\", data.shape)  # rows, columns\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(data.info())\n",
        "\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "print(\"\\nColumns in Dataset:\")\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "id": "0MfurTrI8v07",
        "outputId": "2e52496a-e896-4cdc-c669-0f154b18318c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (891, 12)\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Summary Statistics:\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
            "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
            "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
            "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
            "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
            "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
            "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
            "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  891.000000  891.000000  \n",
            "mean     0.381594   32.204208  \n",
            "std      0.806057   49.693429  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.910400  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.000000  \n",
            "max      6.000000  512.329200  \n",
            "\n",
            "Missing Values per Column:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "Columns in Dataset:\n",
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering\n",
        "\n",
        "#Extract Title from Name\n",
        "data['Title'] = data['Name'].str.extract(r\",\\s*([^\\.]+)\\.\", expand=False).str.strip()\n",
        "\n",
        "#Simplify rare titles\n",
        "rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major',\n",
        "               'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
        "data['Title'] = data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
        "data['Title'] = data['Title'].replace(rare_titles, 'Rare')\n",
        "\n",
        "#Create FamilySize\n",
        "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
        "\n",
        "#Create IsAlone\n",
        "data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
        "\n",
        "#Extract CabinLetter\n",
        "data['CabinLetter'] = data['Cabin'].fillna('Unknown').astype(str).str[0]\n",
        "\n",
        "#Fare per person\n",
        "data['FarePerPerson'] = data['Fare'] / data['FamilySize']\n",
        "\n",
        "#Preview updated dataset\n",
        "print(\"Feature engineering completed!\")\n",
        "print(data[['Name','Title','FamilySize','IsAlone','Cabin','CabinLetter','Fare','FarePerPerson']].head())\n"
      ],
      "metadata": {
        "id": "F91yrgIa-v1n",
        "outputId": "8dc9228b-0b3e-48a8-be55-2aafc94f5b2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering completed!\n",
            "                                                Name Title  FamilySize  \\\n",
            "0                            Braund, Mr. Owen Harris    Mr           2   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   Mrs           2   \n",
            "2                             Heikkinen, Miss. Laina  Miss           1   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   Mrs           2   \n",
            "4                           Allen, Mr. William Henry    Mr           1   \n",
            "\n",
            "   IsAlone Cabin CabinLetter     Fare  FarePerPerson  \n",
            "0        0   NaN           U   7.2500        3.62500  \n",
            "1        0   C85           C  71.2833       35.64165  \n",
            "2        1   NaN           U   7.9250        7.92500  \n",
            "3        0  C123           C  53.1000       26.55000  \n",
            "4        1   NaN           U   8.0500        8.05000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define numeric and categorical columns\n",
        "numeric_features = ['Age', 'Fare', 'FamilySize', 'FarePerPerson']\n",
        "categorical_features = ['Sex', 'Pclass', 'Embarked', 'Title', 'IsAlone', 'CabinLetter']\n",
        "\n",
        "#Numeric transformer: fill missing with median, then scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "#Categorical transformer: fill missing with most frequent, then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "#Combine transformers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "#Full pipeline: preprocessing + RandomForest model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42))\n",
        "])\n",
        "\n",
        "print(\"Preprocessing pipeline created successfully!\")"
      ],
      "metadata": {
        "id": "0jkb9CYz-zhz",
        "outputId": "5db56048-1b79-417d-b529-3513af5bb221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing pipeline created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Define features (X) and target (y)\n",
        "X = data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
        "y = data['Survived']\n",
        "\n",
        "#Split into train and validation sets (80% train, 20% validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "#Fit the pipeline on training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "#Predict on validation set\n",
        "y_pred = pipeline.predict(X_val)\n",
        "\n",
        "#Evaluate performance\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\\n\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n"
      ],
      "metadata": {
        "id": "2g8epiIcGXrX",
        "outputId": "7e3e78e9-36d4-4268-a066-f3c0aeb7c3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.7877\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83       110\n",
            "           1       0.75      0.68      0.71        69\n",
            "\n",
            "    accuracy                           0.79       179\n",
            "   macro avg       0.78      0.77      0.77       179\n",
            "weighted avg       0.79      0.79      0.79       179\n",
            "\n",
            "Confusion Matrix:\n",
            "[[94 16]\n",
            " [22 47]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Display the results\n",
        "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
        "print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n"
      ],
      "metadata": {
        "id": "61Ubo3D6KwqZ",
        "outputId": "853c3129-9c4f-4e5f-9eec-5162fb1663a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy Scores: [0.79888268 0.79775281 0.84269663 0.75842697 0.83146067]\n",
            "Mean CV Accuracy: 0.8058\n",
            "Standard Deviation: 0.0296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "#Save the trained pipeline\n",
        "joblib.dump(pipeline, 'titanic_pipeline_model.joblib')\n",
        "print(\"Trained model pipeline saved as 'titanic_pipeline_model.joblib'\")\n",
        "\n",
        "#Save evaluation metrics\n",
        "metrics = {\n",
        "    'accuracy': [accuracy],\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df.to_csv('metrics.csv', index=False)\n",
        "print(\"Validation metrics saved as 'metrics.csv'\")"
      ],
      "metadata": {
        "id": "apDCRtHiLf4Y",
        "outputId": "a2db4265-d3d7-4273-af8a-424c3855f98e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model pipeline saved as 'titanic_pipeline_model.joblib'\n",
            "Validation metrics saved as 'metrics.csv'\n"
          ]
        }
      ]
    }
  ]
}